---
layout: article
title: 【Blog】2025-10 Daily logs
aside:
  toc: true
key: work_reflection
date: 2025-10-15 14:30:07 -0700
tags:
- 301-work-blog
category: [work, Blog]
typora-root-url: ../../../blog
---

# 2025-10 Work logs

## 10-15

1. Llama_factory框架里面碰到了NCCL训练不起来的问题，主要是下面这个情况

```bash
[rank3]:[E1015 21:01:55.063535226 ProcessGroupNCCL.cpp:1484] [PG ID 0 PG GUID 0(default_pg) Rank 3] ProcessGroupNCCL's watchdog got stuck for 1024 seconds without making progress in monitoring enqueued collectives. This typically indicates a NCCL/CUDA API (e.g., CudaEventDestroy) hang blocking the watchdog, and could be triggered by another thread holding the GIL inside a CUDA api (for example, CudaEventDestroy), or other deadlock-prone behaviors.If you suspect the watchdog is not actually stuck and a longer timeout would help, you can either increase the timeout (TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC) to a larger value or disable the heartbeat monitor (TORCH_NCCL_ENABLE_MONITORING=0).If either of aforementioned helps, feel free to file an issue to PyTorch about the short timeout or false positive abort; otherwise, please attempt to debug the hang. 
```

NCCL的timeout原来设置的是480s，已经调大了，但是还没有用，第一个Step都没有训练起来，但是用下面的这个参数能训练

```yaml
buffer_size: 2048
dataloader_num_workers: 1
preprocessing_batch_size: 32
```

所以感觉是数据IO造成的问题，因为这几个参数主要影响的是数据IO的速度。但同时offer了一个情况是，去掉unversal_reason这个文本数据，就能跑起来了，但其实文本数据的IO并不会存在瓶颈，单独训练universal_reason数据速度非常快，所以是否是单纯巧合，可以去掉这个数据跑一下。但最好的排查方法还是直接开启NCCL的info log，检查NCCL的问题到底出现在哪里。

Update1: 去掉text，对结果没有任何实质影响；再去掉视频数据试试，也可能是本地mammoth_single_image的问题，因为那个是本地文件读取的，可能也比较慢（但也不一定，因为单独训练这个数据是没问题的），或者是Finevision的Qwen3数据，可以再试试把这个拿出来看看

Update2: 单独Finevision的Qwen3数据也没什么问题，这就很奇怪了……干脆其他的数据先不用了吧，Qwen3的这批数据应该已经够好了。



2. RL训练

通用任务的RLVR训练价值有多大？比如我们费劲搞出来了一个Reward Model，这个Reward Model能帮助最终模型涨几个点？

从opencompass上自己评估的结果上看起来，Mimo-VL的SFT和RL版本的通用能力差别很小，主要是数学能力提升比较大；

Internvl3.5倒是有比较详细的ablation，但压根没对比通用任务。所以通用任务提升可能在引入一个RM之后不一定能有提升。

目前可以



## 10.16

```bash
flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs
```

出上面这个错误的时候，就是得重新build一遍flash-attn，直接

```
pip install flash-attn==2.8.2 # 得选择一个没装过的版本，现场build一遍。
```

不是，Qwen2VL的模型怎么这么离谱，attn heads=28，还没办法vllm shard到8张卡上，服了

今日任务

- [x] 技术方案规划；
- [ ] RM集成到RLVR框架里面
- [ ] SFT冷启动数据cluster

额，今天都快结束了，后面两个都没搞，Skywork那个Reward Model需要用原生的，value head是单独存储的，这个我是能理解，因为TRL那个库确实是这样的。不过这样就需要自己集成一下模型到VLLM里面，需要花费一些时间测一下精度。

## 10.20

- [ ] VLM Training
  - [ ] RM集成到RLVR框架里面
  - [ ] SFT冷启动数据cluster
  - [x] 论文的topic
- [ ] Personal
  - [ ] 交公积金
- [ ] Biz
  - [x] Title改Prompt
  - [ ] 脚本相关自动化评估优化

我必须承认，网络世界的用语是比较浅薄和简单的，视听时间长了，语言表述能力的下降是必然。所以还是应该让自己多进行有效的阅读，用更精准的词汇表达自己的境况，用更场景化和拟人的手法让更多人听懂。

今日问题

```bash
ModuleNotFoundError: No module named "vllm._C"
# Issue page:
https://github.com/vllm-project/vllm/issues/1814
```

主要原因：使用的文件夹有vllm同名的folder，如果是故意的，需要在local dir里面重新build vllm

```python
pip3 install -e .[vllm]
```

但如果原来装过，build会报错，想了个新的办法，直接在local创建一个venv环境，然后再build看行不行

不行，还是会fail掉，

```python
ubprocess.CalledProcessError: Command '['cmake', '/mnt/bn/chengru-nas/codes/vllm_reward', '-G', 'Ninja', '-DCMAKE_BUILD_TYPE=RelWithDebInfo', '-DVLLM_TARGET_DEVICE=cuda', '-DVLLM_PYTHON_EXECUTABLE=/mnt/bn/chengru-nas/codes/vllm_reward/.venv/bin/python3', '-DVLLM_PYTHON_PATH=/mnt/bn/chengru-nas/codes/vllm_reward/.venv/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process:/tmp/pip-build-env-t_5d2_tl/site:/usr/lib/python311.zip:/usr/lib/python3.11:/usr/lib/python3.11/lib-dynload:/tmp/pip-build-env-t_5d2_tl/overlay/lib/python3.11/site-packages:/tmp/pip-build-env-t_5d2_tl/normal/lib/python3.11/site-packages:/tmp/pip-build-env-t_5d2_tl/overlay/lib/python3.11/site-packages/setuptools/_vendor', '-DFETCHCONTENT_BASE_DIR=/mnt/bn/chengru-nas/codes/vllm_reward/.deps', '-DNVCC_THREADS=1', '-DCMAKE_JOB_POOL_COMPILE:STRING=compile', '-DCMAKE_JOB_POOLS:STRING=compile=208', '-DCMAKE_CUDA_COMPILER=/usr/local/cuda/bin/nvcc']' returned non-zero exit status 1.
```

问题解决了，对于每个新的docker，重新clone再build一遍就能work，不要在原有folder上build

```bash
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -U -e .
```

为什么必须重新build一遍能work，因为`_C.abi3.so`，`_flashmla_extension_C.abi3.so`这些文件都是在编译时候现场build到文件目录里面的，和你机器本身的环境有非常大的关系，因此必须



- **论文相关**：1月份要能赶工出来一篇论文还是比较难的，既要业务跟得上，还要文章能发表，资源也非常有限；还是以个人发展为主，每天要抽出至少两小时时间，只专注做发论文这一件事情，而不是在很多事情上做。

> 如果目标就是发论文，前期可以非常发散的去看论文，然后想Idea，不用局限在某个topic上，不然会限制可能存在的novelty。与此同时，海量的阅读论文，并在阅读后积极思考
>
> 1. 根据这篇文章被启发的Idea是什么？
> 2. 有没有什么类似的工作已经做过这个Idea？
> 3. 如果是你来做，能做成的概率是多少？

## 10.21

- [ ] VLM Training
  - [x] vllm reward：搞完了，但是精度没有对齐
  - [x] SFT Training小规模验证实验
- [ ] 论文
  - [ ] 产出2-3个Idea
- [ ] Biz
  - [ ] P2V 3.0 Report指标
    - [ ] 自动评估的分数？Precision Recall
    - [ ] 卖点方向的迭代进展；



paper Ideas

1. 首先研究下Visual Reasoning错误的情况到底是由于什么引起的？
2. 如果是视觉相关引起的，那么添加怎样的Reward比较合理。

## 10.22

- [ ] VLM Training
  - [x] 小规模验证评估
  - [ ] SFT冷启动数据cluster

WTF，今天基本上什么也没干，就是把评估上的一些问题修复了，修复完之后，加上训练的结果，指标一下涨了6个点，快能和现在最好的同size模型掰下手腕了；

训练也没干什么特别的，就直接用了Qwen3-VL最大模型刷出来的数据，虽然Prompt Mixture有点讲究，但其实讲究不太大。

## 10.28

