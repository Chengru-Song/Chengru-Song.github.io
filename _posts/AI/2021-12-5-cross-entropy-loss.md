---
layout: article
title: 【AI】Cross Entropy Loss详解
sidebar:
  nav: AI
aside:
  toc: true
key: cross_entropy
tags:
- 301-work-ai
- 301-work-basics
- 301-work-interview
category: [AI, AI_Basics]
---
# Cross-entropy loss

Usage: Optimize classifier.

Main idea:

It measures the distance between predicted output probability distribution and actual probability distribution. 

[https://gombru.github.io/2018/05/23/cross_entropy_loss/](https://gombru.github.io/2018/05/23/cross_entropy_loss/)