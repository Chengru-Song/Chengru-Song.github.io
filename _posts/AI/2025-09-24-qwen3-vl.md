---
layout: article
title: 【AI】Qwen3-VL结合代码详解
sidebar:
  nav: AI
aside:
  toc: true
key: llm
date: 2025-09-24 19:46:07 +0800
tags:
- 301-work-ai
category: [AI, AI_Algorithms, Vision]
typora-root-url: ../../../blog
mermaid: true
---

# Qwen3-VL结合代码详解

## 前言

Qwen3-VL终于发布了，这个目前基于Qwen3本身的最大size的LLM训练出来的benchmark是非常不错的，这里跟进一下Qwen3-VL的模型框架，并分析一下架构的变化实际上带来的提升有多少。

## 都有哪些变化

### 为什么要更新架构？

先讲下我自己的理解，以下几个问题，只能从架构的层面解决

1. **更细粒度的视觉语义特征**：来自视觉的语义特征，除非给LLM输入所有pixels，否则丢掉就是丢失，无论如何训练，都无法提升效果；
2. **encode不同维度的特征**：主要是视频层面的，如果不能encode时序特征，则和时序相关的任务模型可能都难以完成。

Visual Reasoning的能力，更多来自于语言模型，可以通过训练搞定，但是以上需要从架构设计时就考虑在内。

### Qwen2.5到Qwen3的变化

1. 位置编码的变化：
